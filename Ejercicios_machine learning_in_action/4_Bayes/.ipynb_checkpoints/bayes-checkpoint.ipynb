{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "# NAIVE BAYES\n",
    "# TRANSFORMAR TEXTO EN UN VECTOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import bayes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Caragamos fuente de información"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "listOPosts,listClasses = bayes.loadDataSet()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Creamos una lista con el  vocabulario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "myVocabList = bayes.createVocabList(listOPosts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['has',\n",
       " 'him',\n",
       " 'problems',\n",
       " 'steak',\n",
       " 'love',\n",
       " 'flea',\n",
       " 'quit',\n",
       " 'maybe',\n",
       " 'dalmation',\n",
       " 'so',\n",
       " 'posting',\n",
       " 'please',\n",
       " 'not',\n",
       " 'how',\n",
       " 'dog',\n",
       " 'licks',\n",
       " 'help',\n",
       " 'mr',\n",
       " 'take',\n",
       " 'park',\n",
       " 'to',\n",
       " 'garbage',\n",
       " 'stupid',\n",
       " 'worthless',\n",
       " 'ate',\n",
       " 'I',\n",
       " 'stop',\n",
       " 'buying',\n",
       " 'my',\n",
       " 'cute',\n",
       " 'is',\n",
       " 'food']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myVocabList"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Con setOfWords2Vec creamos un vector de 0's y 1's del tamaño de nuestra lista. Al recibir el argumento nos mostrará 1 en cada entrada que esté una palabra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "bayes.setOfWords2Vec(myVocabList, listOPosts[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bayes.setOfWords2Vec(myVocabList, listOPosts[3])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "\n",
    "# Cálculo de probabilidades a partir de vectores de palabras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Carguemos los datos de valores precargados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "listOPosts,listClasses = bayes.loadDataSet()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Ahora crearemos una lista de todas nuestras palabras en myVocabList."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "myVocabList = bayes.createVocabList(listOPosts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "trainMat=[]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### El siguiente ciclo rellena la lista trainMat con vectores de palabra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "for postinDoc in listOPosts:\n",
    "    trainMat.append(bayes.setOfWords2Vec(myVocabList, postinDoc))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " [0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " [0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0],\n",
       " [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " [0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1]]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainMat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Ahora vamos a obtener las probabilidades de ser abusivo y los dos vectores de probabilidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "p0V,p1V,pAb=bayes.trainNB0(trainMat,listClasses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pAb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.04166667,  0.08333333,  0.04166667,  0.04166667,  0.04166667,\n",
       "        0.04166667,  0.        ,  0.        ,  0.04166667,  0.04166667,\n",
       "        0.        ,  0.04166667,  0.        ,  0.04166667,  0.04166667,\n",
       "        0.04166667,  0.04166667,  0.04166667,  0.        ,  0.        ,\n",
       "        0.04166667,  0.        ,  0.        ,  0.        ,  0.04166667,\n",
       "        0.04166667,  0.04166667,  0.        ,  0.125     ,  0.04166667,\n",
       "        0.04166667,  0.        ])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p0V\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.        ,  0.05263158,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.05263158,  0.05263158,  0.        ,  0.        ,\n",
       "        0.05263158,  0.        ,  0.05263158,  0.        ,  0.10526316,\n",
       "        0.        ,  0.        ,  0.        ,  0.05263158,  0.05263158,\n",
       "        0.05263158,  0.05263158,  0.15789474,  0.10526316,  0.        ,\n",
       "        0.        ,  0.05263158,  0.05263158,  0.        ,  0.        ,\n",
       "        0.        ,  0.05263158])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p1V\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Modificando el clasificador para las condiciones del mundo real"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Inicializaremos todos los conteos de ocurrencia a 1, e inicializaremos los denominadores a 2. Para esto cambiaremos un par de líneas de  trainNB0() \n",
    "#### p0Num = ones(numWords); p1Num = ones(numWords)\n",
    "#### p0Denom = 2.0; p1Denom = 2.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Cuando vamos a calcular el producto  muchos de estos números son muy pequeños, eventualmete  Python redondea a 0. Una solución a esto es tomar el logaritmo natural de este producto por lo que cambiaremos un par de líneas mas\n",
    "#### p1Vect = log(p1Num/p1Denom)\n",
    "#### p0Vect = log(p0Num/p0Denom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['love', 'my', 'dalmation'] classified as:  0\n",
      "['stupid', 'garbage'] classified as:  1\n"
     ]
    }
   ],
   "source": [
    "bayes.testingNB()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Modelo bag-of-words (bolsa de palabras)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Clasificar correo spam con naïve Bayes \n",
    "#### Para usar naïve Bayes  en algunos problemas de la vida real, tendremos que poder pasar de un cuerpo de texto a una lista de cadenas y luego un vector de palabras.\n",
    "####  Si se tiene una cadena de texto, puede dividirla utilizando el método .split () de cadena Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "mySent='This book is the best book on Python or M.L. I have ever laid eyes upon.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This',\n",
       " 'book',\n",
       " 'is',\n",
       " 'the',\n",
       " 'best',\n",
       " 'book',\n",
       " 'on',\n",
       " 'Python',\n",
       " 'or',\n",
       " 'M.L.',\n",
       " 'I',\n",
       " 'have',\n",
       " 'ever',\n",
       " 'laid',\n",
       " 'eyes',\n",
       " 'upon.']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mySent.split()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "###  Funciona bien, pero la puntuación se considera parte de la palabra.\n",
    "### Podemos utilizar expresiones regulares para dividir la oración en cualquier cosa que no sea una palabra o un número"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "regEx = re.compile('\\\\W*')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/site-packages/ipykernel_launcher.py:1: FutureWarning: split() requires a non-empty pattern match.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "listOfTokens = regEx.split(mySent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This',\n",
       " 'book',\n",
       " 'is',\n",
       " 'the',\n",
       " 'best',\n",
       " 'book',\n",
       " 'on',\n",
       " 'Python',\n",
       " 'or',\n",
       " 'M',\n",
       " 'L',\n",
       " 'I',\n",
       " 'have',\n",
       " 'ever',\n",
       " 'laid',\n",
       " 'eyes',\n",
       " 'upon',\n",
       " '']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listOfTokens\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Ahora se  tiene una lista de palabras. Pero hay algunas cadenas vacías de las que necesitamos deshacernos.\n",
    "### Podemos contar la longitud de cada cadena y devolver sólo los elementos mayores que 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This',\n",
       " 'book',\n",
       " 'is',\n",
       " 'the',\n",
       " 'best',\n",
       " 'book',\n",
       " 'on',\n",
       " 'Python',\n",
       " 'or',\n",
       " 'M',\n",
       " 'L',\n",
       " 'I',\n",
       " 'have',\n",
       " 'ever',\n",
       " 'laid',\n",
       " 'eyes',\n",
       " 'upon']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[tok for tok in listOfTokens if len(tok) > 0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Finalmente, la primera palabra de la oración inicia con mayúscula. Si estuviera mirando frases, esto sería útil. Pero estamos mirando una bolsa de palabras, así que quieres que todas las palabras se vean iguales si están en el medio, el final o el comienzo de una oración.\n",
    "\n",
    "### Python tiene métodos integrados para convertir cadenas a todas las letras minúsculas (.lower ()) o todas las mayúsculas (.upper ()). Esto resolverá nuestro problema. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Obtengamos nuestra nueva lista por comprensión como sigue:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['this',\n",
       " 'book',\n",
       " 'is',\n",
       " 'the',\n",
       " 'best',\n",
       " 'book',\n",
       " 'on',\n",
       " 'python',\n",
       " 'or',\n",
       " 'm',\n",
       " 'l',\n",
       " 'i',\n",
       " 'have',\n",
       " 'ever',\n",
       " 'laid',\n",
       " 'eyes',\n",
       " 'upon']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[tok.lower() for tok in listOfTokens if len(tok) > 0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Ahora vamos a ver esto en acción con un correo electrónico completo de nuestro conjunto de datos de correo electrónico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "emailText = open('email/ham/6.txt', encoding = \"ISO-8859-1\").read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/site-packages/ipykernel_launcher.py:1: FutureWarning: split() requires a non-empty pattern match.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "listOfTokens=regEx.split(emailText)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello',\n",
       " 'Since',\n",
       " 'you',\n",
       " 'are',\n",
       " 'an',\n",
       " 'owner',\n",
       " 'of',\n",
       " 'at',\n",
       " 'least',\n",
       " 'one',\n",
       " 'Google',\n",
       " 'Groups',\n",
       " 'group',\n",
       " 'that',\n",
       " 'uses',\n",
       " 'the',\n",
       " 'customized',\n",
       " 'welcome',\n",
       " 'message',\n",
       " 'pages',\n",
       " 'or',\n",
       " 'files',\n",
       " 'we',\n",
       " 'are',\n",
       " 'writing',\n",
       " 'to',\n",
       " 'inform',\n",
       " 'you',\n",
       " 'that',\n",
       " 'we',\n",
       " 'will',\n",
       " 'no',\n",
       " 'longer',\n",
       " 'be',\n",
       " 'supporting',\n",
       " 'these',\n",
       " 'features',\n",
       " 'starting',\n",
       " 'February',\n",
       " '2011',\n",
       " 'We',\n",
       " 'made',\n",
       " 'this',\n",
       " 'decision',\n",
       " 'so',\n",
       " 'that',\n",
       " 'we',\n",
       " 'can',\n",
       " 'focus',\n",
       " 'on',\n",
       " 'improving',\n",
       " 'the',\n",
       " 'core',\n",
       " 'functionalities',\n",
       " 'of',\n",
       " 'Google',\n",
       " 'Groups',\n",
       " 'mailing',\n",
       " 'lists',\n",
       " 'and',\n",
       " 'forum',\n",
       " 'discussions',\n",
       " 'Instead',\n",
       " 'of',\n",
       " 'these',\n",
       " 'features',\n",
       " 'we',\n",
       " 'encourage',\n",
       " 'you',\n",
       " 'to',\n",
       " 'use',\n",
       " 'products',\n",
       " 'that',\n",
       " 'are',\n",
       " 'designed',\n",
       " 'specifically',\n",
       " 'for',\n",
       " 'file',\n",
       " 'storage',\n",
       " 'and',\n",
       " 'page',\n",
       " 'creation',\n",
       " 'such',\n",
       " 'as',\n",
       " 'Google',\n",
       " 'Docs',\n",
       " 'and',\n",
       " 'Google',\n",
       " 'Sites',\n",
       " 'For',\n",
       " 'example',\n",
       " 'you',\n",
       " 'can',\n",
       " 'easily',\n",
       " 'create',\n",
       " 'your',\n",
       " 'pages',\n",
       " 'on',\n",
       " 'Google',\n",
       " 'Sites',\n",
       " 'and',\n",
       " 'share',\n",
       " 'the',\n",
       " 'site',\n",
       " 'http',\n",
       " 'www',\n",
       " 'google',\n",
       " 'com',\n",
       " 'support',\n",
       " 'sites',\n",
       " 'bin',\n",
       " 'answer',\n",
       " 'py',\n",
       " 'hl',\n",
       " 'en',\n",
       " 'answer',\n",
       " '174623',\n",
       " 'with',\n",
       " 'the',\n",
       " 'members',\n",
       " 'of',\n",
       " 'your',\n",
       " 'group',\n",
       " 'You',\n",
       " 'can',\n",
       " 'also',\n",
       " 'store',\n",
       " 'your',\n",
       " 'files',\n",
       " 'on',\n",
       " 'the',\n",
       " 'site',\n",
       " 'by',\n",
       " 'attaching',\n",
       " 'files',\n",
       " 'to',\n",
       " 'pages',\n",
       " 'http',\n",
       " 'www',\n",
       " 'google',\n",
       " 'com',\n",
       " 'support',\n",
       " 'sites',\n",
       " 'bin',\n",
       " 'answer',\n",
       " 'py',\n",
       " 'hl',\n",
       " 'en',\n",
       " 'answer',\n",
       " '90563',\n",
       " 'on',\n",
       " 'the',\n",
       " 'site',\n",
       " 'If',\n",
       " 'you',\n",
       " 're',\n",
       " 'just',\n",
       " 'looking',\n",
       " 'for',\n",
       " 'a',\n",
       " 'place',\n",
       " 'to',\n",
       " 'upload',\n",
       " 'your',\n",
       " 'files',\n",
       " 'so',\n",
       " 'that',\n",
       " 'your',\n",
       " 'group',\n",
       " 'members',\n",
       " 'can',\n",
       " 'download',\n",
       " 'them',\n",
       " 'we',\n",
       " 'suggest',\n",
       " 'you',\n",
       " 'try',\n",
       " 'Google',\n",
       " 'Docs',\n",
       " 'You',\n",
       " 'can',\n",
       " 'upload',\n",
       " 'files',\n",
       " 'http',\n",
       " 'docs',\n",
       " 'google',\n",
       " 'com',\n",
       " 'support',\n",
       " 'bin',\n",
       " 'answer',\n",
       " 'py',\n",
       " 'hl',\n",
       " 'en',\n",
       " 'answer',\n",
       " '50092',\n",
       " 'and',\n",
       " 'share',\n",
       " 'access',\n",
       " 'with',\n",
       " 'either',\n",
       " 'a',\n",
       " 'group',\n",
       " 'http',\n",
       " 'docs',\n",
       " 'google',\n",
       " 'com',\n",
       " 'support',\n",
       " 'bin',\n",
       " 'answer',\n",
       " 'py',\n",
       " 'hl',\n",
       " 'en',\n",
       " 'answer',\n",
       " '66343',\n",
       " 'or',\n",
       " 'an',\n",
       " 'individual',\n",
       " 'http',\n",
       " 'docs',\n",
       " 'google',\n",
       " 'com',\n",
       " 'support',\n",
       " 'bin',\n",
       " 'answer',\n",
       " 'py',\n",
       " 'hl',\n",
       " 'en',\n",
       " 'answer',\n",
       " '86152',\n",
       " 'assigning',\n",
       " 'either',\n",
       " 'edit',\n",
       " 'or',\n",
       " 'download',\n",
       " 'only',\n",
       " 'access',\n",
       " 'to',\n",
       " 'the',\n",
       " 'files',\n",
       " 'you',\n",
       " 'have',\n",
       " 'received',\n",
       " 'this',\n",
       " 'mandatory',\n",
       " 'email',\n",
       " 'service',\n",
       " 'announcement',\n",
       " 'to',\n",
       " 'update',\n",
       " 'you',\n",
       " 'about',\n",
       " 'important',\n",
       " 'changes',\n",
       " 'to',\n",
       " 'Google',\n",
       " 'Groups',\n",
       " '']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listOfTokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "###  Notemos que ahora tenemos palabras como \"en\" y \"py\" porque originalmente formaban parte de una URL: /answer.py?hl=en&answer=174623. Cuando dividimos la URL recibimos muchas palabras. Nos gustaría deshacernos de estas palabras, así que filtraremos palabras con menos de tres caracteres.\n",
    "\n",
    "### Utilizamos una regla general de análisis de texto para este ejemplo. En un programa de análisis del mundo real, debería tener filtros más avanzados que busquen cosas como HTML y URL's.\n",
    "\n",
    "### En este momento, un URL terminará como una de nuestras palabras; por ejemplo Www.whitehouse.gov terminará como tres palabras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Validación cruzada con naïve Bayes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification error ['codeine', '15mg', 'for', '203', 'visa', 'only', 'codeine', 'methylmorphine', 'narcotic', 'opioid', 'pain', 'reliever', 'have', '15mg', '30mg', 'pills', '15mg', 'for', '203', '15mg', 'for', '385', '15mg', 'for', '562', 'visa', 'only']\n",
      "classification error ['oem', 'adobe', 'microsoft', 'softwares', 'fast', 'order', 'and', 'download', 'microsoft', 'office', 'professional', 'plus', '2007', '2010', '129', 'microsoft', 'windows', 'ultimate', '119', 'adobe', 'photoshop', 'cs5', 'extended', 'adobe', 'acrobat', 'pro', 'extended', 'windows', 'professional', 'thousand', 'more', 'titles']\n",
      "classification error ['experience', 'with', 'biggerpenis', 'today', 'grow', 'inches', 'more', 'the', 'safest', 'most', 'effective', 'methods', 'of_penisen1argement', 'save', 'your', 'time', 'and', 'money', 'bettererections', 'with', 'effective', 'ma1eenhancement', 'products', 'ma1eenhancement', 'supplement', 'trusted', 'millions', 'buy', 'today']\n",
      "classification error ['bargains', 'here', 'buy', 'phentermin', 'buy', 'genuine', 'phentermin', 'low', 'cost', 'visa', 'accepted', '130', '219', '292', '120', '366', '180', '513']\n",
      "classification error ['home', 'based', 'business', 'opportunity', 'knocking', 'your', 'door', 'don', 'rude', 'and', 'let', 'this', 'chance', 'you', 'can', 'earn', 'great', 'income', 'and', 'find', 'your', 'financial', 'life', 'transformed', 'learn', 'more', 'here', 'your', 'success', 'work', 'from', 'home', 'finder', 'experts']\n",
      "classification error ['bargains', 'here', 'buy', 'phentermin', 'buy', 'genuine', 'phentermin', 'low', 'cost', 'visa', 'accepted', '130', '219', '292', '120', '366', '180', '513']\n",
      "the error rate is:  0.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/re.py:203: FutureWarning: split() requires a non-empty pattern match.\n",
      "  return _compile(pattern, flags).split(string, maxsplit)\n"
     ]
    }
   ],
   "source": [
    "bayes.spamTest()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### La función spamTest () muestra la tasa de error de 10 correos electrónicos seleccionados al azar. Dado que estos son seleccionados al azar, los resultados pueden ser diferentes cada vez. Si hay un error, mostrará la lista de palabras de ese documento para darnos una idea de lo que fue clasificado erróneamente. Para obtener una buena estimación de la tasa de error, debe repetir este procedimiento varias veces, digamos 10, y realizar el  promedio de los resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### El error que sigue apareciendo es una pieza de spam que se clasificó erróneamente . Pero es mejor que un pedazo de spam se escabulla a través del filtro que un correo electrónico válido que se mete en la carpeta de correo no deseado."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
